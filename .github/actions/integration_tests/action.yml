name: run integration tests
description: runs linking and dedupe tests on AWS
runs:
  using: "composite"
  steps:
    - name: Checkout repo
      uses: actions/checkout@v2
    - name: Run AWS test
      uses: databricks/run-notebook@v0
      with:
        local-notebook-path: integration-tests/RUN_TESTS.py
        git-commit: ${{ github.event.pull_request.head.sha }}
        databricks-host: https://e2-demo-west.cloud.databricks.com
        databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_AWS }}
        new-cluster-json: >
          {
            "num_workers": 0,
            "spark_version": "11.3.x-cpu-ml-scala2.12",
            "data_security_mode": "SINGLE_USER",
            "node_type_id": "i3.xlarge",
            "aws_attributes": {
                "availability": "ON_DEMAND"
             },
            "spark_conf": {
                 "spark.master": "local[*, 4]",
                 "spark.databricks.cluster.profile": "singleNode"
             },
             "custom_tags": {
                 "ResourceClass": "SingleNode"
             }
          }
        notebook-params-json: >
          {
            "run_job": "True"
          }
        access-control-list-json: >
          [
            {
              "group_name": "users",
              "permission_level": "CAN_VIEW"
            }
          ]
    - name: Run GCP tests
      uses: databricks/run-notebook@v0
      with:
        local-notebook-path: integration-tests/RUN_TESTS.py
        git-commit: ${{ github.event.pull_request.head.sha }}
        databricks-host: https://416411475796958.8.gcp.databricks.com
        databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_GCP }}
        new-cluster-json: >
          {
             "num_workers": 0,
             "spark_version": "11.3.x-cpu-ml-scala2.12",
             "data_security_mode": "SINGLE_USER",
             "node_type_id": "n1-highmem-4",
             "gcp_attributes": {
               "availability": "ON_DEMAND_GCP"
             },
             "spark_conf": {
                 "spark.master": "local[*, 4]",
                 "spark.databricks.cluster.profile": "singleNode"
             },
             "custom_tags": {
                 "ResourceClass": "SingleNode"
             }
           }
        notebook-params-json: >
          {
           "run_job": "True"
          }
        access-control-list-json: >
          [
            {
              "group_name": "users",
              "permission_level": "CAN_VIEW"
            }
          ]
      - name: Run MSA tests
        uses: databricks/run-notebook@v0
        with:
          local-notebook-path: integration-tests/RUN_TESTS.py
          git-commit: ${{ github.event.pull_request.head.sha }}
          databricks-host: https://adb-984752964297111.11.azuredatabricks.net
          databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_MSA }}
          new-cluster-json: >
            {
              "num_workers": 0,
              "spark_version": "11.3.x-cpu-ml-scala2.12",
              "data_security_mode": "SINGLE_USER",
              "node_type_id": "Standard_DS3_v2",
              "azure_attributes": {
                   "availability": "ON_DEMAND_AZURE"
                             },
              "spark_conf": {
                   "spark.master": "local[*, 4]",
                   "spark.databricks.cluster.profile": "singleNode"
               },
               "custom_tags": {
                   "ResourceClass": "SingleNode"
               }

            }
          notebook-params-json: >
            {
             "run_job": "True"
            }
          access-control-list-json: >
            [
              {
                "group_name": "users",
                "permission_level": "CAN_VIEW"
              }
            ]